{
  "url": "https://voxday.net/2018/12/28/whatever-happened-to-trust-safety/",
  "scraped_at": "2025-12-20T05:22:51.722075",
  "title": "Whatever happened to Trust & Safety?",
  "date_display": "December 28, 2018",
  "date_iso": "2018-12-28T01:28:45+00:00",
  "date_from_url": "2018-12-28",
  "author": "VD",
  "content_html": "<div class=\"entry-content\"><p>Federal regulators should keep this news in mind when they’re considering the way in which the big tech platforms speech police and deplatform <a href=\"https://techcrunch.com/2018/12/27/funding-filth/\">while they are funding criminal filth</a>.</p><blockquote><p>Google  has scrambled to remove third-party apps that led users to child porn sharing groups on WhatsApp in the wake of TechCrunch’s report about the problem last week. We contacted Google with the name of one of these apps and evidence that it and others offered links to WhatsApp groups for sharing child exploitation imagery. Following publication of our article, Google removed from the Google Play store that app and at least five like it. Several of these apps had more than 100,000 downloads, and they’re still functional on devices that already downloaded them.</p><p>WhatsApp failed to adequately police its platform, confirming to TechCrunch that it’s only moderated by its own 300 employees and not Facebook’s  20,000 dedicated security and moderation staffers. It’s clear that scalable and efficient artificial intelligence systems are not up to the task of protecting the 1.5 billion-user WhatsApp community, and companies like Facebook must invest more in unscalable human investigators.</p><p>But now, new research provided exclusively to TechCrunch by anti-harassment algorithm startup AntiToxin shows that these removed apps that hosted links to child porn sharing rings on WhatsApp were supported with ads run by Google and Facebook’s ad networks. AntiToxin found six of these apps ran Google AdMob, one ran Google Firebase, two ran Facebook Audience Network and one ran StartApp. These ad networks earned a cut of brands’ marketing spend while allowing the apps to monetize and sustain their operations by hosting ads for Amazon, Microsoft, Motorola, Sprint, Sprite, Western Union, Dyson, DJI, Gett, Yandex Music, Q Link Wireless, Tik Tok and more.</p><p>The situation reveals that tech giants aren’t just failing to spot offensive content in their own apps, but also in third-party apps that host their ads and that earn them money. While these apps like “Group Links For Whats” by Lisa Studio let people discover benign links to WhatsApp groups for sharing legal content and discussing topics like business or sports, TechCrunch found they also hosted links with titles such as “child porn only no adv” and “child porn xvideos” that led to WhatsApp groups with names like “Children ???” or “videos cp” — a known abbreviation for “child pornography.”</p></blockquote><p>They “scrambled” to remove them. But only after they were caught. How is that not a crime? After all, are we not reliably informed that the big tech platforms carefully monitor and patrol their content?</p></div>",
  "content_text": "Federal regulators should keep this news in mind when they’re considering the way in which the big tech platforms speech police and deplatform\nwhile they are funding criminal filth\n.\nGoogle  has scrambled to remove third-party apps that led users to child porn sharing groups on WhatsApp in the wake of TechCrunch’s report about the problem last week. We contacted Google with the name of one of these apps and evidence that it and others offered links to WhatsApp groups for sharing child exploitation imagery. Following publication of our article, Google removed from the Google Play store that app and at least five like it. Several of these apps had more than 100,000 downloads, and they’re still functional on devices that already downloaded them.\nWhatsApp failed to adequately police its platform, confirming to TechCrunch that it’s only moderated by its own 300 employees and not Facebook’s  20,000 dedicated security and moderation staffers. It’s clear that scalable and efficient artificial intelligence systems are not up to the task of protecting the 1.5 billion-user WhatsApp community, and companies like Facebook must invest more in unscalable human investigators.\nBut now, new research provided exclusively to TechCrunch by anti-harassment algorithm startup AntiToxin shows that these removed apps that hosted links to child porn sharing rings on WhatsApp were supported with ads run by Google and Facebook’s ad networks. AntiToxin found six of these apps ran Google AdMob, one ran Google Firebase, two ran Facebook Audience Network and one ran StartApp. These ad networks earned a cut of brands’ marketing spend while allowing the apps to monetize and sustain their operations by hosting ads for Amazon, Microsoft, Motorola, Sprint, Sprite, Western Union, Dyson, DJI, Gett, Yandex Music, Q Link Wireless, Tik Tok and more.\nThe situation reveals that tech giants aren’t just failing to spot offensive content in their own apps, but also in third-party apps that host their ads and that earn them money. While these apps like “Group Links For Whats” by Lisa Studio let people discover benign links to WhatsApp groups for sharing legal content and discussing topics like business or sports, TechCrunch found they also hosted links with titles such as “child porn only no adv” and “child porn xvideos” that led to WhatsApp groups with names like “Children ???” or “videos cp” — a known abbreviation for “child pornography.”\nThey “scrambled” to remove them. But only after they were caught. How is that not a crime? After all, are we not reliably informed that the big tech platforms carefully monitor and patrol their content?",
  "tags": [
    "technology"
  ],
  "categories": [],
  "sitemap_lastmod": "2018-12-28T01:28:45+00:00"
}