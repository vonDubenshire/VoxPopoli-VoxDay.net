{
  "url": "https://voxday.net/2018/12/08/on-the-knowledge-of-god-part-ii/",
  "scraped_at": "2025-12-20T05:20:05.194556",
  "title": "On the knowledge of God, part II",
  "date_display": "December 8, 2018",
  "date_iso": "2018-12-08T18:00:12+00:00",
  "date_from_url": "2018-12-08",
  "author": "VD",
  "content_html": "<div class=\"entry-content\"><p>This continues from <a href=\"http://voxday.blogspot.com/2018/12/on-knowledge-of-god-part-i.html\">the previous post</a> on divine intelligence and is a selection from the same chapter of <i>The Irrational Atheist</i>.</p><p>Despite the evidence and the logic presented previously, the skeptical reader may well ask if there isn’t at least some element of omniscience or even omniderigence implied in the assertion of God’s omnipotence. How can an all-powerful god not know what is going on around him? And is it really conceivable to imagine an all-powerful being sitting idly by and refusing to intervene in the affairs of humanity as they unfold? The answer, surprisingly enough, is suggested by Daniel C. Dennett in one of his more technical books.</p><p><b>Gods of the Machine</b><br>First, there is the activity of our hacker Gods, who are free to cast their eyes and minds over huge manifolds of possible Life worlds, trying to figure out what will tend to work, what will be robust and what will be fragile. For the time being, we are supposing that they are truly God-like in their “miraculous” interactions with the Life world – they are not bound by the slow speed of glider­light; they can intervene, reaching in and tweaking the design of a creation whenever they like, stopping the Life world in mid-collision, undoing the harm and going back to the drawing board to create a new design.<br>– Daniel Dennett, <i>Freedom Evolves</i></br></br></p><p>I am, as you may recall from the introduction, a game designer.1 Most of my experience has been with designing and producing computer games for the DOS/Windows platform, and I think it would be safe to say that the best adjective to describe my career would be “innovative” rather than “successful”. In 1996, following the release of id Software’s <i>Quake</i>, my partner and I began designing our first true 3D game for GT Interactive. Our two previous games had been of the 2.5D first-person shooter variety, and although we managed to do some interesting and lucrative things with speech recognition technology and hardware bundling deals, we had not yet achieved the sort of market success or recognition within the game industry that we sought.</p><p>Youthful hubris, combined with a desire to surpass id’s legendary pair of John Carmack and John Romero, led us to create a supremely ambitious design. Not only would we create our own 3D engine, but we would also create a multi-tiered artificial intelligence system that would allow for complete cooperation and two-way verbal interaction with AI-controlled squadmates fighting an opposition force made up of separate artificial intelligences in a three-dimensional, non-Euclidean world. The insane impracticality of this design can be seen in the way that ten years later, no electronic game has yet demonstrated even half of the technologies required to fully realize the concepts with which we were working. Nor are they likely to any time soon, as the success of Valve’s <i>Half-Life</i> showed that gamers were perfectly happy playing through pre-programmed scripted scenarios, which requires neither sophisticated artificial intelligences nor complex synthetic speech systems.</p><p>The financial collapse of our publisher forced us to abandon this design, but not before we had managed to develop a significant chunk of both the TacAI, which governed individual activities such as ducking, dodging and laying down covering fire, as well as the StratAI, which made decisions about larger scale, goal-related matters such as what target its troops should be attacking first, when reinforcements should be summoned and when to fall back to a stronger position. Ironically, considering the topic of this book, we made use of a genetic programming approach in developing these artificial intelligences, a technique that makes use of evolutionary algorithms in an unnatural selection scheme favoring the survival of the optimally performing, or if you will, the fittest.</p><p>In this game world, the lead programmer, Big Chilly, reigned supreme. He was, precisely as Dennett describes the hacker gods of the Life world, quite literally omnipotent from the perspective of its denizens, able to create thunder, hurl lightning, shake the earth, create sickness or grant health according to his whim. He could perform miracles such as stopping time or even making time flow backwards, he could grant one character invulnerability while striking another dead in an instant. He was omniscient too, able to peek into an AI’s “mind” to see what actions it intended as well as taking in the entire world at a glance. That which was unseen by the characters was not hidden from him, and he operated entirely outside their temporal references. Whereas they moved about in conventional time on a second-by-second basis, he had the ability to examine their movements in time-slices ranging from one-quarter to one-thirty-fifth of a second.</p><p>In short, Big Chilly was not only their creator, he was their God.</p><p>And while it would have been incredibly interesting had these artificial intelligences become self- aware and begun worshipping him, the project unfortunately came to an end before that could happen thanks to circumstances beyond our control. However, it didn’t end before something of some relevance to the subject of this chapter took place.</p><p>Not long before our publisher, GT Interactive, went out of business, we were demonstrating the game to our executive producer and a few other GT employees. Big Chilly was playing through a POW rescue mission, a mission which he and others on the development team had played hundreds of times before throughout the course of playtesting. The mission involved one fireteam of AI troops making a diversionary attack on one side of the enemy base while the player led a second team around the other side to rescue the prisoners. Being the lead programmer, Big Chilly of course knew where all of the enemy troops were located because he was responsible for assigning their starting positions, and while the specific results of the scenario varied from one playing to another, the degree to which both friendly and enemy troop behavior varied from the norm was well-known.</p><p>During the demo, Big Chilly and the three AI-controlled members of his fireteam had successfully taken out both the wide patrol and the guards, and they were just beginning to lay the explosives to blow the door that held the prisoners captive when there was a sudden burst of bright laser fire that caused him to jump in his seat and emit a startled shriek loud enough to make everyone else in the room jump too. While his AI squadmates shot down the intruder before anyone’s battlesuits took too much damage, what shocked Big Chilly was that for the first time in hundreds of playings and tens of thousands of simulations, an enemy AI had taken it upon itself to circle around behind the rescue force and attack it from an unexpected direction.</p><p>But how could this happen? How could a lowly artificial intelligence surprise a lead programmer who was demonstrably omniscient and omnipotent in the AI’s world? How can the created do what the creator did not will? The answer, when viewed in this context, should be obvious.</p><p>Surprise was possible because the programmer <i>was choosing not to exercise either his knowledge or his power</i> at that particular point where real-time intersected game-time. While he could have easily provided that particular character with a scripted path and prevented the character from being able to depart from it, he had already elected not to do so. He could have constructed the character in such a way that its head would have exploded for the sin of attempted deicide, or even as punishment for the sin of merely daring to look upon him in all his pasty geek glory, but he did not do that either. And finally, while he could have been scanning that particular AI’s “thought” processes and known what it intended to do in the very instant the intention was born, instead he refrained and so learned about its actions through entirely “natural” means.</p><p>If it is not difficult to accept that an omniscient and omnipotent programmer can reject omniderigence, why should it be hard to imagine that an all-powerful God might not choose to do the same? Even human lovers know that the lover cannot control the beloved, so it should not be difficult to believe that a loving God would permit His creatures to choose freely how they will live.</p></div>",
  "content_text": "This continues from\nthe previous post\non divine intelligence and is a selection from the same chapter of\nThe Irrational Atheist\n.\nDespite the evidence and the logic presented previously, the skeptical reader may well ask if there isn’t at least some element of omniscience or even omniderigence implied in the assertion of God’s omnipotence. How can an all-powerful god not know what is going on around him? And is it really conceivable to imagine an all-powerful being sitting idly by and refusing to intervene in the affairs of humanity as they unfold? The answer, surprisingly enough, is suggested by Daniel C. Dennett in one of his more technical books.\nGods of the Machine\nFirst, there is the activity of our hacker Gods, who are free to cast their eyes and minds over huge manifolds of possible Life worlds, trying to figure out what will tend to work, what will be robust and what will be fragile. For the time being, we are supposing that they are truly God-like in their “miraculous” interactions with the Life world – they are not bound by the slow speed of glider­light; they can intervene, reaching in and tweaking the design of a creation whenever they like, stopping the Life world in mid-collision, undoing the harm and going back to the drawing board to create a new design.\n– Daniel Dennett,\nFreedom Evolves\nI am, as you may recall from the introduction, a game designer.1 Most of my experience has been with designing and producing computer games for the DOS/Windows platform, and I think it would be safe to say that the best adjective to describe my career would be “innovative” rather than “successful”. In 1996, following the release of id Software’s\nQuake\n, my partner and I began designing our first true 3D game for GT Interactive. Our two previous games had been of the 2.5D first-person shooter variety, and although we managed to do some interesting and lucrative things with speech recognition technology and hardware bundling deals, we had not yet achieved the sort of market success or recognition within the game industry that we sought.\nYouthful hubris, combined with a desire to surpass id’s legendary pair of John Carmack and John Romero, led us to create a supremely ambitious design. Not only would we create our own 3D engine, but we would also create a multi-tiered artificial intelligence system that would allow for complete cooperation and two-way verbal interaction with AI-controlled squadmates fighting an opposition force made up of separate artificial intelligences in a three-dimensional, non-Euclidean world. The insane impracticality of this design can be seen in the way that ten years later, no electronic game has yet demonstrated even half of the technologies required to fully realize the concepts with which we were working. Nor are they likely to any time soon, as the success of Valve’s\nHalf-Life\nshowed that gamers were perfectly happy playing through pre-programmed scripted scenarios, which requires neither sophisticated artificial intelligences nor complex synthetic speech systems.\nThe financial collapse of our publisher forced us to abandon this design, but not before we had managed to develop a significant chunk of both the TacAI, which governed individual activities such as ducking, dodging and laying down covering fire, as well as the StratAI, which made decisions about larger scale, goal-related matters such as what target its troops should be attacking first, when reinforcements should be summoned and when to fall back to a stronger position. Ironically, considering the topic of this book, we made use of a genetic programming approach in developing these artificial intelligences, a technique that makes use of evolutionary algorithms in an unnatural selection scheme favoring the survival of the optimally performing, or if you will, the fittest.\nIn this game world, the lead programmer, Big Chilly, reigned supreme. He was, precisely as Dennett describes the hacker gods of the Life world, quite literally omnipotent from the perspective of its denizens, able to create thunder, hurl lightning, shake the earth, create sickness or grant health according to his whim. He could perform miracles such as stopping time or even making time flow backwards, he could grant one character invulnerability while striking another dead in an instant. He was omniscient too, able to peek into an AI’s “mind” to see what actions it intended as well as taking in the entire world at a glance. That which was unseen by the characters was not hidden from him, and he operated entirely outside their temporal references. Whereas they moved about in conventional time on a second-by-second basis, he had the ability to examine their movements in time-slices ranging from one-quarter to one-thirty-fifth of a second.\nIn short, Big Chilly was not only their creator, he was their God.\nAnd while it would have been incredibly interesting had these artificial intelligences become self- aware and begun worshipping him, the project unfortunately came to an end before that could happen thanks to circumstances beyond our control. However, it didn’t end before something of some relevance to the subject of this chapter took place.\nNot long before our publisher, GT Interactive, went out of business, we were demonstrating the game to our executive producer and a few other GT employees. Big Chilly was playing through a POW rescue mission, a mission which he and others on the development team had played hundreds of times before throughout the course of playtesting. The mission involved one fireteam of AI troops making a diversionary attack on one side of the enemy base while the player led a second team around the other side to rescue the prisoners. Being the lead programmer, Big Chilly of course knew where all of the enemy troops were located because he was responsible for assigning their starting positions, and while the specific results of the scenario varied from one playing to another, the degree to which both friendly and enemy troop behavior varied from the norm was well-known.\nDuring the demo, Big Chilly and the three AI-controlled members of his fireteam had successfully taken out both the wide patrol and the guards, and they were just beginning to lay the explosives to blow the door that held the prisoners captive when there was a sudden burst of bright laser fire that caused him to jump in his seat and emit a startled shriek loud enough to make everyone else in the room jump too. While his AI squadmates shot down the intruder before anyone’s battlesuits took too much damage, what shocked Big Chilly was that for the first time in hundreds of playings and tens of thousands of simulations, an enemy AI had taken it upon itself to circle around behind the rescue force and attack it from an unexpected direction.\nBut how could this happen? How could a lowly artificial intelligence surprise a lead programmer who was demonstrably omniscient and omnipotent in the AI’s world? How can the created do what the creator did not will? The answer, when viewed in this context, should be obvious.\nSurprise was possible because the programmer\nwas choosing not to exercise either his knowledge or his power\nat that particular point where real-time intersected game-time. While he could have easily provided that particular character with a scripted path and prevented the character from being able to depart from it, he had already elected not to do so. He could have constructed the character in such a way that its head would have exploded for the sin of attempted deicide, or even as punishment for the sin of merely daring to look upon him in all his pasty geek glory, but he did not do that either. And finally, while he could have been scanning that particular AI’s “thought” processes and known what it intended to do in the very instant the intention was born, instead he refrained and so learned about its actions through entirely “natural” means.\nIf it is not difficult to accept that an omniscient and omnipotent programmer can reject omniderigence, why should it be hard to imagine that an all-powerful God might not choose to do the same? Even human lovers know that the lover cannot control the beloved, so it should not be difficult to believe that a loving God would permit His creatures to choose freely how they will live.",
  "tags": [
    "Christianity"
  ],
  "categories": [],
  "sitemap_lastmod": "2018-12-08T18:00:12+00:00"
}