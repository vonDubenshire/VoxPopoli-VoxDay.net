{
  "url": "https://voxday.net/2018/10/11/ai-is-sexist/",
  "scraped_at": "2025-12-20T05:12:15.533185",
  "title": "AI is sexist",
  "date_display": "October 11, 2018",
  "date_iso": "2018-10-11T12:10:47+00:00",
  "date_from_url": "2018-10-11",
  "author": "VD",
  "content_html": "<div class=\"entry-content\"><p>Amazon <a href=\"https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G\">ditches its HR-replacement AI</a> for violating several of its assumptions:</p><blockquote><p>Amazon.com Inc’s machine-learning specialists uncovered a big problem: their new recruiting engine did not like women.</p><p>The team had been building computer programs since 2014 to review job applicants’ resumes with the aim of mechanizing the search for top talent, five people familiar with the effort told Reuters.</p><p>Automation has been key to Amazon’s e-commerce dominance, be it inside warehouses or driving pricing decisions. The company’s experimental hiring tool used artificial intelligence to give job candidates scores ranging from one to five stars – much like shoppers rate products on Amazon, some of the people said.</p><p>“Everyone wanted this holy grail,” one of the people said. “They literally wanted it to be an engine where I’m going to give you 100 resumes, it will spit out the top five, and we’ll hire those.”</p><p>But by 2015, the company realized its new system was not rating candidates for software developer jobs and other technical posts in a gender-neutral way.</p></blockquote><p>The problem of the machine not spitting out results preferred by those using it is hardly new. And while the article claims that “gender bias was not the only issue” and that “problems with the data that underpinned the models’ judgments meant that unqualified candidates were often recommended for all manner of jobs” is almost certainly true, the problem is that Amazon did not give its AI a fair shake.</p><p>Amazon simply assumed that the undesired preference for male employees and “unqualified candidates” was a bug rather than the feature that it may have been. If the AI actually worked, then it would have undermined not only the concept of sexual equality, but credentialism as well. But instead of actually allowing the experiment to proceed and seeing if those unqualified male candidates recommended by the AI were successful employees, they chose to kill it on the basis of its violation of their preconceived ideas.</p><p>It’s too bad that they didn’t allow the experiment to play out, because the complete destruction of corporate credentialism is desperately needed in today’s increasingly competitive global marketplace. Then again, given how Amazon already dominates the online retail space, it’s probably just as well for their competitors that they turned away from the possible advantage the AI-HR system might have given them.</p></div>",
  "content_text": "Amazon\nditches its HR-replacement AI\nfor violating several of its assumptions:\nAmazon.com Inc’s machine-learning specialists uncovered a big problem: their new recruiting engine did not like women.\nThe team had been building computer programs since 2014 to review job applicants’ resumes with the aim of mechanizing the search for top talent, five people familiar with the effort told Reuters.\nAutomation has been key to Amazon’s e-commerce dominance, be it inside warehouses or driving pricing decisions. The company’s experimental hiring tool used artificial intelligence to give job candidates scores ranging from one to five stars – much like shoppers rate products on Amazon, some of the people said.\n“Everyone wanted this holy grail,” one of the people said. “They literally wanted it to be an engine where I’m going to give you 100 resumes, it will spit out the top five, and we’ll hire those.”\nBut by 2015, the company realized its new system was not rating candidates for software developer jobs and other technical posts in a gender-neutral way.\nThe problem of the machine not spitting out results preferred by those using it is hardly new. And while the article claims that “gender bias was not the only issue” and that “problems with the data that underpinned the models’ judgments meant that unqualified candidates were often recommended for all manner of jobs” is almost certainly true, the problem is that Amazon did not give its AI a fair shake.\nAmazon simply assumed that the undesired preference for male employees and “unqualified candidates” was a bug rather than the feature that it may have been. If the AI actually worked, then it would have undermined not only the concept of sexual equality, but credentialism as well. But instead of actually allowing the experiment to proceed and seeing if those unqualified male candidates recommended by the AI were successful employees, they chose to kill it on the basis of its violation of their preconceived ideas.\nIt’s too bad that they didn’t allow the experiment to play out, because the complete destruction of corporate credentialism is desperately needed in today’s increasingly competitive global marketplace. Then again, given how Amazon already dominates the online retail space, it’s probably just as well for their competitors that they turned away from the possible advantage the AI-HR system might have given them.",
  "tags": [
    "technology"
  ],
  "categories": [],
  "sitemap_lastmod": "2018-10-11T11:10:47+00:00"
}