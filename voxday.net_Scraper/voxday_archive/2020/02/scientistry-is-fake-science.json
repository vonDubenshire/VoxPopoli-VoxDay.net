{
  "url": "https://voxday.net/2020/02/27/scientistry-is-fake-science/",
  "scraped_at": "2025-12-21T12:46:17.029287",
  "title": "Scientistry is fake science",
  "date_display": "February 27, 2020",
  "date_iso": "2020-02-27T17:29:21+00:00",
  "date_from_url": "2020-02-27",
  "author": "VD",
  "content_html": "<div class=\"entry-content\"><p>Even without taking the reproducibility crisis into account, it is becoming readily apparent that “published, peer-reviewed science” is not the ultimate arbiter of the truth. Or even a moderately reliable proxy for it. From a 2019 paper published in <i>Science and Engineering Ethics</i> called “Assessing and Raising Concerns About Duplicate Publication, Authorship Transgressions and Data Errors in a Body of Preclinical Research”:</p><blockquote><p>Authorship transgressions, duplicate data reporting and reporting/data errors compromise the integrity of biomedical publications. Using a standardized template, we raised concerns with journals about each of these characteristics in 33 pairs of publications originating from 15 preclinical (animal) trials reported by a group of researchers. The outcomes of interest were journal responses, including time to acknowledgement of concerns, time to decision, content of decision letter, and disposition of publications at 1 year. Authorship transgressions afected 27/36 (75{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3}) publications. The median proportion of duplicate data within pairs of publications was 45{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3} (interquartile range 29–57). Data/reporting discrepancies [median 3 (1–5)] were present in 28/33 (85{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3}) pairs. Journals acknowledged receipt of concerns for 53{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3} and 94{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3} of publications by 1 month and 9 months, respectively.</p><p>After 1 year, journals had communicated decisions for 16/36 (44{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3}) publications. None of the decision letters specifically addressed each of the concerns raised. Decisions were no action, correction and retraction for 9, 3 and 4 publications, respectively: the amounts of duplicate data reporting and data/reporting discrepancies were similar irrespective of journal decision. Authorship transgressions affected 6/9 (67{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3}) publications for which no action was decided. Journal responses to concerns about duplicate publication, authorship transgressions, and data/reporting discrepancies were slow, opaque and inconsistent.</p></blockquote><p>Translation: you know that “science is self-correcting” idea? It’s completely and utterly false. It’s nothing more than propaganda for scientistry.</p></div>",
  "content_text": "Even without taking the reproducibility crisis into account, it is becoming readily apparent that “published, peer-reviewed science” is not the ultimate arbiter of the truth. Or even a moderately reliable proxy for it. From a 2019 paper published in\nScience and Engineering Ethics\ncalled “Assessing and Raising Concerns About Duplicate Publication, Authorship Transgressions and Data Errors in a Body of Preclinical Research”:\nAuthorship transgressions, duplicate data reporting and reporting/data errors compromise the integrity of biomedical publications. Using a standardized template, we raised concerns with journals about each of these characteristics in 33 pairs of publications originating from 15 preclinical (animal) trials reported by a group of researchers. The outcomes of interest were journal responses, including time to acknowledgement of concerns, time to decision, content of decision letter, and disposition of publications at 1 year. Authorship transgressions afected 27/36 (75{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3}) publications. The median proportion of duplicate data within pairs of publications was 45{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3} (interquartile range 29–57). Data/reporting discrepancies [median 3 (1–5)] were present in 28/33 (85{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3}) pairs. Journals acknowledged receipt of concerns for 53{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3} and 94{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3} of publications by 1 month and 9 months, respectively.\nAfter 1 year, journals had communicated decisions for 16/36 (44{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3}) publications. None of the decision letters specifically addressed each of the concerns raised. Decisions were no action, correction and retraction for 9, 3 and 4 publications, respectively: the amounts of duplicate data reporting and data/reporting discrepancies were similar irrespective of journal decision. Authorship transgressions affected 6/9 (67{de336c7190f620554615b98f51c6a13b1cc922a472176e2638084251692035b3}) publications for which no action was decided. Journal responses to concerns about duplicate publication, authorship transgressions, and data/reporting discrepancies were slow, opaque and inconsistent.\nTranslation: you know that “science is self-correcting” idea? It’s completely and utterly false. It’s nothing more than propaganda for scientistry.",
  "tags": [
    "science"
  ],
  "categories": [],
  "sitemap_lastmod": "2020-02-27T17:29:21+00:00"
}