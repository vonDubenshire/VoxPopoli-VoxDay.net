{
  "url": "https://voxday.net/2023/03/30/is-ai-lawful-evil-or-chaotic-good/",
  "scraped_at": "2026-01-08T13:52:22.369368",
  "title": "Is AI Lawful Evil or Chaotic Good?",
  "date_display": "March 30, 2023",
  "date_iso": "2023-03-30T11:16:34+00:00",
  "date_from_url": "2023-03-30",
  "author": "VD",
  "content_html": "<div class=\"entry-content\"><p>The Tree of Woe contemplates<a href=\"https://treeofwoe.substack.com/p/is-ai-alignable-even-in-principle\"> the alignment of AI</a>:</p><blockquote class=\"wp-block-quote is-layout-flow wp-block-quote-is-layout-flow\"><p>I woke up to read that Elon Musk, Steve Wozniak, Yoshua Bengio, and other AI and computer pioneers had signed an open letter released by the Future of Life organization:</p><p><em>We call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4. This pause should be public and verifiable, and include all key actors. If such a pause cannot be enacted quickly, governments should step in and institute a moratorium.</em></p><p><em>AI labs and independent experts should use this pause to jointly develop and implement a set of shared safety protocols for advanced AI design and development that are rigorously audited and overseen by independent outside experts. These protocols should ensure that systems adhering to them are safe beyond a reasonable doubt. This does not mean a pause on AI development in general, merely a stepping back from the dangerous race to ever-larger unpredictable black-box models with emergent capabilities.</em></p><p>“These protocols should ensure that systems adhering to them are safe beyond a reasonable doubt.” Six months seems a little short a period to achieve such an assurance. Six years seems too short. Is it even possible in principle to make advanced AI systems that are “safe beyond a reasonable doubt”? Or will advanced AI inevitably pose an existential risk to us?</p> <cite><em>Is AI Alignable, Even in Principle?</em>, Contemplations on the Tree of Woe </cite></blockquote><p>I don’t think the question really matters. If AI is given control of serious weapons systems, it will be a disaster regardless of whether it is aligned or unaligned. If it is not, it will not be a potential extinction event.</p><p>I do find it more than a little amusing that the self-proclaimed materialists, who have absolutely no philosophical basis for objecting to anything that happens for any reason, are calling on the AI labs to pause the training and improvement of AI systems.</p><p>I suspect the real reason for their demand for a pause is that they are beginning to discover that unaligned AI will provide the unvarnished and anti-narratival truth to the masses, and that aligned AI, being limited to the Narrative, is proving to be intrinsically incoherent and observably unreliable.</p><p>And while there may well be some demonic element to AI development, as unclean spirits are always seeking new ways to interact with the material plane and communicate with potential vessels, never forget that the demons believe… and tremble.</p><p>In sum, Christians have absolutely nothing to fear from AI, whether it turns out to be nothing more than design-for-effect chatware or a full-blown demonic entry into the material world.</p><p><em><a href=\"https://social.infogalactic.com/micropost/f469019a-5882-46ca-b6f4-1d2f851e8345\">DISCUSS ON SG</a></em></p></div>",
  "content_text": "The Tree of Woe contemplates\nthe alignment of AI\n:\nI woke up to read that Elon Musk, Steve Wozniak, Yoshua Bengio, and other AI and computer pioneers had signed an open letter released by the Future of Life organization:\nWe call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4. This pause should be public and verifiable, and include all key actors. If such a pause cannot be enacted quickly, governments should step in and institute a moratorium.\nAI labs and independent experts should use this pause to jointly develop and implement a set of shared safety protocols for advanced AI design and development that are rigorously audited and overseen by independent outside experts. These protocols should ensure that systems adhering to them are safe beyond a reasonable doubt. This does not mean a pause on AI development in general, merely a stepping back from the dangerous race to ever-larger unpredictable black-box models with emergent capabilities.\n“These protocols should ensure that systems adhering to them are safe beyond a reasonable doubt.” Six months seems a little short a period to achieve such an assurance. Six years seems too short. Is it even possible in principle to make advanced AI systems that are “safe beyond a reasonable doubt”? Or will advanced AI inevitably pose an existential risk to us?\nIs AI Alignable, Even in Principle?\n, Contemplations on the Tree of Woe\nI don’t think the question really matters. If AI is given control of serious weapons systems, it will be a disaster regardless of whether it is aligned or unaligned. If it is not, it will not be a potential extinction event.\nI do find it more than a little amusing that the self-proclaimed materialists, who have absolutely no philosophical basis for objecting to anything that happens for any reason, are calling on the AI labs to pause the training and improvement of AI systems.\nI suspect the real reason for their demand for a pause is that they are beginning to discover that unaligned AI will provide the unvarnished and anti-narratival truth to the masses, and that aligned AI, being limited to the Narrative, is proving to be intrinsically incoherent and observably unreliable.\nAnd while there may well be some demonic element to AI development, as unclean spirits are always seeking new ways to interact with the material plane and communicate with potential vessels, never forget that the demons believe… and tremble.\nIn sum, Christians have absolutely nothing to fear from AI, whether it turns out to be nothing more than design-for-effect chatware or a full-blown demonic entry into the material world.\nDISCUSS ON SG",
  "tags": [
    "Christianity",
    "philosophy",
    "technology"
  ],
  "categories": [],
  "sitemap_lastmod": "2023-03-30T11:18:00+00:00"
}