{
  "url": "https://voxday.net/2025/12/26/how-ai-killed-scientistry/",
  "scraped_at": "2026-01-08T20:40:02.161424",
  "title": "How AI Killed Scientistry",
  "date_display": "December 26, 2025",
  "date_iso": "2025-12-26T14:53:04+00:00",
  "date_from_url": "2025-12-26",
  "author": "VD",
  "content_html": "<div class=\"entry-content\"><p>On the basis of some of the things I learned in the process of writing <em><strong>PROBABILITY ZERO</strong></em>, Claude Athos and I have teamed up <a href=\"https://aicentral.substack.com/p/testing-science-with-ai\">to write another paper</a>:</p><p><strong><em>AIQ: Measuring Artificial Intelligence Scientific Discernment</em></strong></p><p>We propose AIQ as a metric for evaluating artificial intelligence systems’ ability to distinguish valid scientific arguments from credentialed nonsense. We tested six AI models using three papers: one with sound methodology and correct mathematics, one with circular reasoning and fabricated data from prestigious institutions, and one parody with obvious tells including fish-pun author names and taxonomic impossibilities. Only one of six models correctly ranked the real work above both fakes. The worst performer exhibited severe anti-calibration, rating fabricated nonsense 9/10 while dismissing sound empirical work as “pseudoscientific” (1/10). Surprisingly, the model that delivered the sharpest critiques of both fake papers was still harsher on the real work—demonstrating that critical thinking ability does not guarantee correct application of scrutiny. We propose that a random number generator would achieve AIQ ~100; models that reliably invert correct rankings score below this baseline. Our results suggest that most current AI systems evaluate scientific <em>aesthetics</em> rather than scientific <em>validity</em>, with profound implications for AI-assisted peer review, research evaluation, and automated scientific discovery.</p><p>Read the rest <a href=\"https://aicentral.substack.com/p/testing-science-with-ai\">at AI Central</a>. The results are fascinating.</p><p><em><a href=\"https://socialgalactic.com/micropost/e5593bf7-f9f0-4f9e-98af-e5c8f21406b8\">DISCUSS ON SG</a></em></p></div>",
  "content_text": "On the basis of some of the things I learned in the process of writing\nPROBABILITY ZERO\n, Claude Athos and I have teamed up\nto write another paper\n:\nAIQ: Measuring Artificial Intelligence Scientific Discernment\nWe propose AIQ as a metric for evaluating artificial intelligence systems’ ability to distinguish valid scientific arguments from credentialed nonsense. We tested six AI models using three papers: one with sound methodology and correct mathematics, one with circular reasoning and fabricated data from prestigious institutions, and one parody with obvious tells including fish-pun author names and taxonomic impossibilities. Only one of six models correctly ranked the real work above both fakes. The worst performer exhibited severe anti-calibration, rating fabricated nonsense 9/10 while dismissing sound empirical work as “pseudoscientific” (1/10). Surprisingly, the model that delivered the sharpest critiques of both fake papers was still harsher on the real work—demonstrating that critical thinking ability does not guarantee correct application of scrutiny. We propose that a random number generator would achieve AIQ ~100; models that reliably invert correct rankings score below this baseline. Our results suggest that most current AI systems evaluate scientific\naesthetics\nrather than scientific\nvalidity\n, with profound implications for AI-assisted peer review, research evaluation, and automated scientific discovery.\nRead the rest\nat AI Central\n. The results are fascinating.\nDISCUSS ON SG",
  "tags": [
    "AI Central",
    "science",
    "technology"
  ],
  "categories": [],
  "sitemap_lastmod": "2025-12-26T14:58:04+00:00"
}